{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2c8f5e-7c07-456a-9f58-4c212039c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openpyxl\n",
    "import os\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.width',1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Note: only load the shapefile dataframe when needed to merge. This will inflate the filesize of the generated csv\n",
    "\n",
    "# shp_path = os.path.join('..', 'philippines-psgc-shapefiles', 'philippines-psgc-shapefiles', 'data', '2023', 'Municities', 'phl_admbnda_adm3_psa_namria_20231106.shp')\n",
    "# shape_file_df = gpd.read_file(shp_path)\n",
    "# map_df = shape_file_df[['ADM3_EN', 'ADM2_EN', 'ADM1_EN', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5964a0-de57-4a20-9864-98687d94855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Constants\n",
    "\n",
    "SAVE_FILE_TYPE = 'csv'\n",
    "YEARS = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca2dec-069a-416b-a351-ee5ed455d848",
   "metadata": {},
   "source": [
    "# Processing Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746030a6-4838-42a8-98ec-329d9ff77daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Summary Statistics: 100%|███████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "CPU times: total: 2.09 s\n",
      "Wall time: 2.26 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def preprocess_port_data(file_path):\n",
    "\n",
    "    data = pd.read_excel(file_path, header=[0, 1, 2, 3])\n",
    "    \n",
    "    new_columns = []\n",
    "    for col in data.columns:\n",
    "        col_names = [str(c).strip() for c in col if 'Unnamed' not in str(c)]\n",
    "        new_col_name = ' | '.join(col_names) if col_names else 'Unknown'\n",
    "        new_columns.append(new_col_name)\n",
    "    \n",
    "    data.columns = new_columns\n",
    "    data.dropna(how='all', axis=1, inplace=True)\n",
    "    data = data.loc[~(data.map(lambda x: pd.isna(x) or str(x).strip() == '')).all(axis=1)]\n",
    "    \n",
    "    data.dropna(how='all', axis=0, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Hardcode renaming the first three columns to 'Category 1', 'Category 2', 'Category 3'\n",
    "    data.columns.values[0] = 'Category 1'\n",
    "    data.columns.values[1] = 'Category 2'\n",
    "    data.columns.values[2] = 'Category 3'\n",
    "\n",
    "    # Add the quarter to the 'TOTAL' column names correctly\n",
    "    quarters = ['1st Quarter', '2nd Quarter', '3rd Quarter', '4th Quarter']\n",
    "    for quarter in quarters:\n",
    "        for i, col in enumerate(data.columns):\n",
    "            if col == 'TOTAL' and i > 0 and quarter in data.columns[i+1]:\n",
    "                data.columns.values[i] = f'{quarter} TOTAL'\n",
    "\n",
    "    # Fix 'GRAND TOTAL' columns\n",
    "    data.columns = [col.replace('GRAND TOTAL | ', 'GRAND TOTAL | ') for col in data.columns]\n",
    "    data.columns = [col.replace('Unknown', '') for col in data.columns]\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data['Category 1'].ffill(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "for year in tqdm(YEARS, desc='Processing Summary Statistics'):\n",
    "    file_path = os.path.join('..', '[DATA] Ports Files', 'Raw Files', year, f'{year}SummaryStatistics.xlsx')\n",
    "    save_path = os.path.join('..', '[DATA] Ports Files', 'Standardized', 'Summary Statistics', f'{year}SummaryStatistics.{SAVE_FILE_TYPE}')\n",
    "    cleaned_data = preprocess_port_data(file_path)\n",
    "    cleaned_data.to_csv(save_path, index=False)\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab316f-b168-412e-8626-a607f20fe4e2",
   "metadata": {},
   "source": [
    "# Processing Shipping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92b497c-7b92-4289-9d0f-6fbdb83a856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Shipping data: 100%|████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "CPU times: total: 18.8 s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def map_city(pmo, pier_terminal):\n",
    "    \"\"\"Map the city based on PMO and Pier/Terminal using the provided mapping.\"\"\"\n",
    "    mapping_file = os.path.join('..', 'port_city_mapper.json')\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        port_city_mapper = json.load(f)\n",
    "    \n",
    "    if pd.isna(pmo) or pd.isna(pier_terminal):\n",
    "        return pier_terminal\n",
    "    \n",
    "    pmo = pmo.upper()\n",
    "    pier_terminal = pier_terminal.upper()\n",
    "    \n",
    "    if pmo in port_city_mapper:\n",
    "        for key in port_city_mapper[pmo]:\n",
    "            if key in pier_terminal:\n",
    "                return port_city_mapper[pmo][key]\n",
    "    \n",
    "    return pier_terminal\n",
    "\n",
    "def merge_with_shapefile(shipping_df, map_df):\n",
    "    \"\"\"Merge the shipping data with the PSGC shapefile data.\"\"\"\n",
    "    mapping_file = os.path.join('..', 'ambiguos_cities.json')\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        ambiguous_mapping = json.load(f)\n",
    "    \n",
    "    # Ensure all values are uppercase\n",
    "    shipping_df['city_mapping_shp'] = shipping_df['city_mapping_shp'].str.upper()\n",
    "    shipping_df['ADM2_EN'] = shipping_df['city_mapping_shp'].map(ambiguous_mapping).fillna('').str.upper()\n",
    "    map_df['ADM3_EN'] = map_df['ADM3_EN'].str.upper()\n",
    "    map_df['ADM2_EN'] = map_df['ADM2_EN'].str.upper()\n",
    "\n",
    "    # Merge normally where there is no ambiguity\n",
    "    normal_merge = shipping_df[~shipping_df['city_mapping_shp'].isin(ambiguous_mapping.keys())].merge(\n",
    "        map_df, left_on='city_mapping_shp', right_on='ADM3_EN', how='left')\n",
    "\n",
    "    # Merge with ADM2_EN for ambiguous cases\n",
    "    ambiguous_merge = shipping_df[shipping_df['city_mapping_shp'].isin(ambiguous_mapping.keys())].merge(\n",
    "        map_df, left_on=['city_mapping_shp', 'ADM2_EN'], right_on=['ADM3_EN', 'ADM2_EN'], how='left')\n",
    "    \n",
    "    # Concatenate the results\n",
    "    merged_df = pd.concat([normal_merge, ambiguous_merge], ignore_index=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def is_bold(cell):\n",
    "    \"\"\"Check if the cell text is bold.\"\"\"\n",
    "    try:\n",
    "        return cell.font.bold\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def preprocess_shipping_data(file_path, sheet_name):\n",
    "    \"\"\"\n",
    "    Preprocesses an Excel sheet from shipping data, handling multi-level headers,\n",
    "    detecting bold cells, reformatting specific columns, and identifying the base rows\n",
    "    for each hierarchical category before forward filling, with base indicators as integers.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The file path of the Excel file.\n",
    "        sheet_name (str): The sheet name to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed DataFrame with cleaned, formatted, and enhanced data.\n",
    "    \"\"\"\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = wb[sheet_name]\n",
    "\n",
    "    data, bold_info = [], []\n",
    "    for row in sheet.iter_rows(values_only=False):\n",
    "        row_data, row_bold = [], []\n",
    "        for cell in row:\n",
    "            row_data.append(cell.value)\n",
    "            row_bold.append(is_bold(cell))\n",
    "        data.append(row_data)\n",
    "        bold_info.append(row_bold)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    headers = df.iloc[:4].fillna('').astype(str).agg(' | '.join)\n",
    "    df.columns = headers\n",
    "    df = df.iloc[4:].reset_index(drop=True)\n",
    "\n",
    "    new_columns = []\n",
    "    previous_category = \"\"\n",
    "    for col in df.columns:\n",
    "        if 'Total' in col:\n",
    "            previous_category = col.split('|')[0].strip()\n",
    "        new_col_name = ' | '.join(c.strip() for c in col.split('|') if c.strip())\n",
    "        if 'Domestic' in new_col_name or 'Foreign' in new_col_name:\n",
    "            new_col_name = f\"{previous_category} | {new_col_name}\"\n",
    "        new_columns.append(new_col_name)\n",
    "\n",
    "    df.columns = new_columns\n",
    "    df.columns.values[0:3] = ['Region', 'PMO', 'Port']\n",
    "\n",
    "    is_bold_list = [1 if bold_row[2] else 0 for bold_row in bold_info[4:len(df)+4]]\n",
    "    df['is_bold'] = is_bold_list\n",
    "    df['Pier/Terminal'] = df.apply(lambda row: row['Port'] if row['is_bold'] == 0 else None, axis=1)\n",
    "    df.drop(columns=['is_bold'], inplace=True)\n",
    "    df['Port'] = df.apply(lambda row: None if row['Pier/Terminal'] == row['Port'] else row['Port'], axis=1)\n",
    "\n",
    "    df.dropna(how='all', axis=1, inplace=True)\n",
    "    df = df.loc[~(df.map(lambda x: pd.isna(x) or str(x).strip() == '')).all(axis=1)]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    column_order = ['Region', 'PMO', 'Port', 'Pier/Terminal'] + [col for col in df.columns if col not in ['Region', 'PMO', 'Port', 'Pier/Terminal']]\n",
    "    df = df[column_order]\n",
    "\n",
    "    df['Region'] = df['Region'].ffill()\n",
    "    df['PMO'] = df.groupby('Region')['PMO'].ffill()\n",
    "    df['Port'] = df.groupby(['Region', 'PMO'])['Port'].ffill()\n",
    "    df['Pier/Terminal'] = df.groupby(['Region', 'PMO', 'Port'])['Pier/Terminal'].ffill()\n",
    "\n",
    "    df['is_Region_base'] = (df['Region'].notna() & df['PMO'].isna()).astype(int)\n",
    "    df['is_PMO_base'] = (df['PMO'].notna() & df['Port'].isna()).astype(int)\n",
    "    df['is_Port_base'] = (df['Port'].notna() & df['Pier/Terminal'].isna()).astype(int)\n",
    "    df['is_Pier/Terminal_base'] = df['Pier/Terminal'].notna().astype(int)\n",
    "\n",
    "    # Create city_mapping_shp column\n",
    "    df['city_mapping_shp'] = df.apply(lambda row: map_city(row['PMO'], row['Pier/Terminal']), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "for year in tqdm(YEARS, desc=\"Processing Shipping data\"): \n",
    "    file_path = os.path.join('..', '[DATA] Ports Files', 'Raw Files', year, 'Shipping.xlsx')\n",
    "    save_path = os.path.join('..', '[DATA] Ports Files', 'Standardized', 'Shipping', f'{year} - Shipping.{SAVE_FILE_TYPE}')\n",
    "    sheet_name = 'shipcalls'\n",
    "    cleaned_data = preprocess_shipping_data(file_path, sheet_name)\n",
    "\n",
    "    # May cost time\n",
    "    # merged_data = merge_with_shapefile(cleaned_data, map_df)\n",
    "    # merged_data.to_csv(save_path, index=False)\n",
    "    cleaned_data.to_csv(save_path, index=False)\n",
    "    \n",
    "print(\"Success!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6e0a1-a038-40b7-97ee-2d3525c0ce29",
   "metadata": {},
   "source": [
    "# Processing Passengers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf71de1-2725-447b-89c3-01b6688f9cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Passenger data: 100%|███████████████████████████████████████████████████████| 10/10 [00:36<00:00,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "CPU times: total: 35.5 s\n",
      "Wall time: 36.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def is_bold(cell):\n",
    "    \"\"\"Check if the cell text is bold.\"\"\"\n",
    "    try:\n",
    "        return cell.font.bold\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def fill_and_set_bases(df, bold_info, header_rows):\n",
    "    \"\"\"Fill hierarchical categories and set base indicators, including handling for 'Pier/Terminal'.\"\"\"\n",
    "    # Ensure that the first 3 columns match the following values\n",
    "    df.columns.values[0:3] = ['Region', 'PMO', 'Port']\n",
    "\n",
    "    is_bold_list = [int(bold_row[2]) for bold_row in bold_info[header_rows:len(df)+header_rows]]\n",
    "    \n",
    "    df['is_bold'] = is_bold_list\n",
    "\n",
    "    # Use bold information to differentiate 'Port' and 'Pier/Terminal'\n",
    "    df['Pier/Terminal'] = df.apply(lambda row: row['Port'] if not row['is_bold'] else None, axis=1)\n",
    "    df['Port'] = df.apply(lambda row: row['Port'] if row['is_bold'] else None, axis=1)\n",
    "\n",
    "    # Remove the is_bold helper column as it is no longer needed. You can uncomment this for debugging purposes\n",
    "    df.drop(columns=['is_bold'], inplace=True)\n",
    "\n",
    "    df.dropna(how='all', inplace=True)  \n",
    "\n",
    "    df['Region'] = df['Region'].ffill()\n",
    "    df['PMO'] = df.groupby('Region')['PMO'].ffill()\n",
    "    df['Port'] = df.groupby(['Region', 'PMO'])['Port'].ffill()\n",
    "    df['Pier/Terminal'] = df.groupby(['Region', 'PMO', 'Port'])['Pier/Terminal'].ffill()\n",
    "\n",
    "    df['is_Region_base'] = df['Region'].notna() & df['PMO'].isna()\n",
    "    df['is_PMO_base'] = df['PMO'].notna() & df['Port'].isna()\n",
    "    df['is_Port_base'] = df['Port'].notna()\n",
    "    df['is_Pier/Terminal_base'] = df['Pier/Terminal'].notna()\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_passenger_data(file_path, sheet_name='passengers'):\n",
    "    \"\"\"\n",
    "    Preprocesses an Excel sheet from passenger data, handling multi-level headers,\n",
    "    detecting bold cells, reformatting specific columns, and identifying the base rows\n",
    "    for each hierarchical category before forward filling, with base indicators as integers.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The file path of the Excel file.\n",
    "        sheet_name (str): The sheet name to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed DataFrame with cleaned, formatted, and enhanced data.\n",
    "    \"\"\"\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = wb[sheet_name]\n",
    "\n",
    "    data, bold_info = [], []\n",
    "    for row in sheet.iter_rows(values_only=False):\n",
    "        row_data, row_bold = [], []\n",
    "        for cell in row:\n",
    "            row_data.append(cell.value)\n",
    "            row_bold.append(is_bold(cell))\n",
    "        data.append(row_data)\n",
    "        bold_info.append(row_bold)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    headers = df.iloc[:4].fillna('').astype(str).agg(' | '.join)\n",
    "    df.columns = headers\n",
    "    df = df.iloc[4:].reset_index(drop=True)\n",
    "\n",
    "    new_columns = []\n",
    "    previous_category = \"\"\n",
    "    for col in df.columns:\n",
    "        if 'Total' in col:\n",
    "            previous_category = col.split('|')[0].strip()\n",
    "        new_col_name = ' | '.join(c.strip() for c in col.split('|') if c.strip())\n",
    "        if 'Disembarked' in new_col_name or 'Embarked' in new_col_name or 'Cruise Ships' in new_col_name:\n",
    "            new_col_name = f\"{previous_category} | {new_col_name}\"\n",
    "        new_columns.append(new_col_name)\n",
    "\n",
    "    df.columns = new_columns\n",
    "    df.columns.values[0:3] = ['Region', 'PMO', 'Port']\n",
    "\n",
    "    df = fill_and_set_bases(df, bold_info, 4)\n",
    "\n",
    "    # df.dropna(how='all', axis=1, inplace=True)\n",
    "    df = df.loc[~(df.map(lambda x: pd.isna(x) or str(x).strip() == '')).all(axis=1)]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    column_order = ['Region', 'PMO', 'Port', 'Pier/Terminal'] + [col for col in df.columns if col not in ['Region', 'PMO', 'Port', 'Pier/Terminal']]\n",
    "    df = df[column_order]\n",
    "\n",
    "    df['city_mapping_shp'] = df.apply(lambda row: map_city(row['PMO'], row['Pier/Terminal']), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "for year in tqdm(YEARS, desc=\"Processing Passenger data\"): \n",
    "    file_path = os.path.join('..', '[DATA] Ports Files', 'Raw Files', year, 'Passenger.xlsx')\n",
    "    save_path = os.path.join('..', '[DATA] Ports Files', 'Standardized', 'Passenger', f'{year} - Passenger.{SAVE_FILE_TYPE}')\n",
    "    sheet_name = 'passengers'\n",
    "    cleaned_data = preprocess_passenger_data(file_path, sheet_name)\n",
    "\n",
    "    cleaned_data.to_csv(save_path, index=False)\n",
    "    \n",
    "print(\"Success!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce647d-2ad1-410f-b805-e7cd59f11a70",
   "metadata": {},
   "source": [
    "# Processing Cargo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eabeff59-0bd0-4aa2-8a2a-ba06927ba913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cargo data: 100%|███████████████████████████████████████████████████████████| 10/10 [00:47<00:00,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "CPU times: total: 45.8 s\n",
      "Wall time: 47.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def is_bold(cell):\n",
    "    \"\"\"Check if the cell text is bold.\"\"\"\n",
    "    try:\n",
    "        return cell.font.bold\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def preprocess_cargo_data(file_path, sheet_name='cargo', header_rows=4):\n",
    "    \"\"\"Preprocesses an Excel sheet from cargo data.\"\"\"\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = wb[sheet_name]\n",
    "\n",
    "    data, bold_info = [], []\n",
    "    for row in sheet.iter_rows(values_only=False):\n",
    "        row_data, row_bold = [cell.value for cell in row], [is_bold(cell) for cell in row]\n",
    "        data.append(row_data)\n",
    "        bold_info.append(row_bold)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.dropna(how='all', axis=1, inplace=True)  \n",
    "    \n",
    "    headers = df.iloc[:header_rows].fillna('').astype(str).agg(' | '.join, axis=0)\n",
    "    df.columns = headers\n",
    "    df = df.iloc[header_rows:].reset_index(drop=True)\n",
    "\n",
    "    df.columns = enhance_column_names(df.columns)\n",
    "      \n",
    "\n",
    "    df = fill_and_set_bases(df, bold_info, header_rows)\n",
    "\n",
    "    column_order = ['Region', 'PMO', 'Port', 'Pier/Terminal'] + [col for col in df.columns if col not in ['Region', 'PMO', 'Port', 'Pier/Terminal']]\n",
    "    df = df[column_order]\n",
    "\n",
    "    df['city_mapping_shp'] = df.apply(lambda row: map_city(row['PMO'], row['Pier/Terminal']), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def enhance_column_names(columns):\n",
    "    \"\"\"Enhances column names to include hierarchical information correctly.\"\"\"\n",
    "    new_columns = []\n",
    "    current_month = \"\"\n",
    "    current_category = \"\"\n",
    "    for col in columns:\n",
    "        parts = col.split(' | ')\n",
    "        if 'GRAND TOTAL' in col:\n",
    "            month = parts[0]\n",
    "            if any(m in month for m in ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']):\n",
    "                current_month = month\n",
    "                current_category = \"\"\n",
    "        elif 'DOMESTIC' in col or 'FOREIGN' in col:\n",
    "            current_category = parts[0]\n",
    "        new_header = f\"{current_month} | {current_category} | {' | '.join(parts[1:])}\"\n",
    "        new_columns.append(new_header)\n",
    "    return new_columns\n",
    "\n",
    "def fill_and_set_bases(df, bold_info, header_rows):\n",
    "    \"\"\"Fill hierarchical categories and set base indicators, including handling for 'Pier/Terminal'.\"\"\"\n",
    "    # Pls dont touch these (Although, ensure that first 3 cols match the following vals)\n",
    "    df.columns.values[0:3] = ['Region', 'PMO', 'Port']\n",
    "\n",
    "    is_bold_list = [int(bold_row[2]) for bold_row in bold_info[header_rows:len(df)+header_rows]]\n",
    "\n",
    "    df['is_bold'] = is_bold_list\n",
    "\n",
    "    df['Pier/Terminal'] = df.apply(lambda row: row['Port'] if not row['is_bold'] else None, axis=1)\n",
    "    df['Port'] = df.apply(lambda row: row['Port'] if row['is_bold'] else None, axis=1)\n",
    "\n",
    "    df.drop(columns=['is_bold'], inplace=True)\n",
    "\n",
    "    df.dropna(how='all', inplace=True)  \n",
    "\n",
    "    df['Region'] = df['Region'].ffill()\n",
    "    df['PMO'] = df.groupby('Region')['PMO'].ffill()\n",
    "    df['Port'] = df.groupby(['Region', 'PMO'])['Port'].ffill()\n",
    "    df['Pier/Terminal'] = df.groupby(['Region', 'PMO', 'Port'])['Pier/Terminal'].ffill()\n",
    "\n",
    "    df['is_Region_base'] = df['Region'].notna() & df['PMO'].isna()\n",
    "    df['is_PMO_base'] = df['PMO'].notna() & df['Port'].isna()\n",
    "    df['is_Port_base'] = df['Port'].notna()\n",
    "    df['is_Pier/Terminal_base'] = df['Pier/Terminal'].notna()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "for year in tqdm(YEARS, desc=\"Processing Cargo data\"):\n",
    "    file_path = os.path.join('..', '[DATA] Ports Files', 'Raw Files', year, 'Cargo.xlsx')\n",
    "    save_path = os.path.join('..', '[DATA] Ports Files', 'Standardized', 'Cargo', f'{year} - Cargo.{SAVE_FILE_TYPE}')\n",
    "    sheet_name = 'cargo'\n",
    "    cleaned_data = preprocess_cargo_data(file_path, sheet_name, 4)\n",
    "    \n",
    "    cleaned_data.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f065db-d495-4a83-815d-111055fb8f2a",
   "metadata": {},
   "source": [
    "# Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c52dbd-bc07-4ca8-acfe-38bb45f0fa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Container data: 100%|███████████████████████████████████████████████████████| 10/10 [00:45<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "CPU times: total: 44.2 s\n",
      "Wall time: 45.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "def is_bold(cell):\n",
    "    \"\"\"Check if the cell text is bold.\"\"\"\n",
    "    try:\n",
    "        return cell.font.bold\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def preprocess_container_data(file_path, sheet_name='container', header_rows=4):\n",
    "    \"\"\"Preprocesses an Excel sheet from container data.\"\"\"\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = wb[sheet_name]\n",
    "\n",
    "    data, bold_info = [], []\n",
    "    for row in sheet.iter_rows(values_only=False):\n",
    "        row_data, row_bold = [cell.value for cell in row], [is_bold(cell) for cell in row]\n",
    "        data.append(row_data)\n",
    "        bold_info.append(row_bold)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.dropna(how='all', axis=1, inplace=True)  \n",
    "    \n",
    "    headers = df.iloc[:header_rows].fillna('').astype(str).agg(' | '.join, axis=0)\n",
    "    df.columns = headers\n",
    "    df = df.iloc[header_rows:].reset_index(drop=True)\n",
    "\n",
    "    df.columns = enhance_column_names(df.columns)\n",
    "    # df.dropna(how='all', inplace=True)  \n",
    "\n",
    "    df = fill_and_set_bases(df, bold_info, header_rows)\n",
    "\n",
    "    column_order = ['Region', 'PMO', 'Port', 'Pier/Terminal'] + [col for col in df.columns if col not in ['Region', 'PMO', 'Port', 'Pier/Terminal']]\n",
    "    df = df[column_order]\n",
    "\n",
    "    df['city_mapping_shp'] = df.apply(lambda row: map_city(row['PMO'], row['Pier/Terminal']), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def enhance_column_names(columns):\n",
    "    \"\"\"Enhances column names to include hierarchical information correctly.\"\"\"\n",
    "    new_columns = []\n",
    "    current_month = \"\"\n",
    "    current_category = \"\"\n",
    "    for col in columns:\n",
    "        parts = col.split(' | ')\n",
    "        if 'GRAND TOTAL' in col:\n",
    "            month = parts[0]\n",
    "            if any(m in month for m in ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']):\n",
    "                current_month = month\n",
    "                current_category = \"\"\n",
    "        elif 'DOMESTIC' in col or 'FOREIGN' in col:\n",
    "            current_category = parts[0]\n",
    "        new_header = f\"{current_month} | {current_category} | {' | '.join(parts[1:])}\"\n",
    "        new_columns.append(new_header)\n",
    "    return new_columns\n",
    "\n",
    "def fill_and_set_bases(df, bold_info, header_rows):\n",
    "    \"\"\"Fill hierarchical categories and set base indicators, including handling for 'Pier/Terminal'.\"\"\"\n",
    "    # Pls dont touch these (Although, ensure that first 3 cols match the following vals)\n",
    "    df.columns.values[0:3] = ['Region', 'PMO', 'Port']\n",
    "\n",
    "    is_bold_list = [int(bold_row[2]) for bold_row in bold_info[header_rows:len(df)+header_rows]]\n",
    "\n",
    "    # Shift is_bold list up by one row\n",
    "    # if len(is_bold_list) > 1:\n",
    "    #     is_bold_list = is_bold_list[1:] + [0]\n",
    "    \n",
    "    df['is_bold'] = is_bold_list\n",
    "\n",
    "    df['Pier/Terminal'] = df.apply(lambda row: row['Port'] if not row['is_bold'] else None, axis=1)\n",
    "    df['Port'] = df.apply(lambda row: row['Port'] if row['is_bold'] else None, axis=1)\n",
    "\n",
    "    df.drop(columns=['is_bold'], inplace=True)\n",
    "    df.dropna(how='all', inplace=True)  \n",
    "\n",
    "    df['Region'] = df['Region'].ffill()\n",
    "    df['PMO'] = df.groupby('Region')['PMO'].ffill()\n",
    "    df['Port'] = df.groupby(['Region', 'PMO'])['Port'].ffill()\n",
    "    df['Pier/Terminal'] = df.groupby(['Region', 'PMO', 'Port'])['Pier/Terminal'].ffill()\n",
    "\n",
    "    df['is_Region_base'] = df['Region'].notna() & df['PMO'].isna()\n",
    "    df['is_PMO_base'] = df['PMO'].notna() & df['Port'].isna()\n",
    "    df['is_Port_base'] = df['Port'].notna()\n",
    "    df['is_Pier/Terminal_base'] = df['Pier/Terminal'].notna()\n",
    "\n",
    "    return df\n",
    "\n",
    "file_name = 'Container'\n",
    "\n",
    "for year in tqdm(YEARS, desc=f\"Processing {file_name} data\"):\n",
    "    file_path = os.path.join('..', '[DATA] Ports Files', 'Raw Files', year, f'{file_name}.xlsx')\n",
    "    save_path = os.path.join('..', '[DATA] Ports Files', 'Standardized', file_name, f'{year} - {file_name}.{SAVE_FILE_TYPE}')\n",
    "    sheet_name = 'teu'\n",
    "    cleaned_data = preprocess_container_data(file_path, sheet_name, 4)\n",
    "    cleaned_data.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db707a3d-d273-460a-8eff-72631089f3b1",
   "metadata": {},
   "source": [
    "# RORO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b714930e-bb2d-4543-9092-d1b47c38606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing RORO data: 100%|██████████████████████████████████████████████████████████████| 9/9 [00:48<00:00,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "CPU times: total: 47.2 s\n",
      "Wall time: 48.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def is_bold(cell):\n",
    "    \"\"\"Check if the cell text is bold.\"\"\"\n",
    "    try:\n",
    "        return cell.font.bold\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def preprocess_roro_data(file_path, sheet_name='roro', header_rows=4):\n",
    "    \"\"\"Preprocesses an Excel sheet from roro data.\"\"\"\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = wb[sheet_name]\n",
    "\n",
    "    data, bold_info = [], []\n",
    "    for row in sheet.iter_rows(values_only=False):\n",
    "        row_data, row_bold = [cell.value for cell in row], [is_bold(cell) for cell in row]\n",
    "        data.append(row_data)\n",
    "        bold_info.append(row_bold)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.dropna(how='all', axis=1, inplace=True)  \n",
    "    \n",
    "    headers = df.iloc[:header_rows].fillna('').astype(str).agg(' | '.join, axis=0)\n",
    "    df.columns = headers\n",
    "    df = df.iloc[header_rows:].reset_index(drop=True)\n",
    "\n",
    "    df.columns = enhance_column_names(df.columns)\n",
    "    \n",
    "\n",
    "    df = fill_and_set_bases(df, bold_info, header_rows)\n",
    "    \n",
    "\n",
    "    column_order = ['Region', 'PMO', 'Port', 'Pier/Terminal'] + [col for col in df.columns if col not in ['Region', 'PMO', 'Port', 'Pier/Terminal']]\n",
    "    df = df[column_order]\n",
    "\n",
    "    df['city_mapping_shp'] = df.apply(lambda row: map_city(row['PMO'], row['Pier/Terminal']), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def enhance_column_names(columns):\n",
    "    \"\"\"Enhances column names to include hierarchical information, correctly handling nested categories.\"\"\"\n",
    "    new_columns = []\n",
    "    current_month = \"\"\n",
    "    current_direction = \"\"\n",
    "    current_type = \"\"       \n",
    "\n",
    "    for col in columns:\n",
    "        parts = [part.strip() for part in col.split(' | ') if part.strip()]\n",
    "        if parts:\n",
    "            if any(month in parts[0] for month in ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']):\n",
    "                current_month = parts[0]  \n",
    "                current_direction = \"\" \n",
    "                current_type = \"\"  \n",
    "            if 'Inbound' in parts or 'Outbound' in parts:\n",
    "                current_direction = parts[0] \n",
    "                current_type = \"\"  \n",
    "            if 'Type' in parts[-1]:\n",
    "                current_type = parts[-1]  \n",
    "\n",
    "            if current_type:\n",
    "                new_header = f\"{current_month} | {current_direction} | {current_type}\"\n",
    "            else:\n",
    "                new_header = f\"{current_month} | {current_direction} | {' | '.join(parts[1:])}\"\n",
    "            new_columns.append(new_header)\n",
    "        else:\n",
    "            new_columns.append(f\"{current_month} | {current_direction} | {current_type}\")\n",
    "\n",
    "    return new_columns\n",
    "\n",
    "def fill_and_set_bases(df, bold_info, header_rows):\n",
    "    \"\"\"Fill hierarchical categories and set base indicators, including handling for 'Pier/Terminal'.\"\"\"\n",
    "    # Pls dont touch these (Although, ensure that first 3 cols match the following vals)\n",
    "    df.columns.values[0:3] = ['Region', 'PMO', 'Port']\n",
    "\n",
    "    is_bold_list = [int(bold_row[2]) for bold_row in bold_info[header_rows:len(df)+header_rows]]\n",
    "    \n",
    "    df['is_bold'] = is_bold_list\n",
    "\n",
    "    # Use bold information to differentiate 'Port' and 'Pier/Terminal'\n",
    "    df['Pier/Terminal'] = df.apply(lambda row: row['Port'] if not row['is_bold'] else None, axis=1)\n",
    "    df['Port'] = df.apply(lambda row: row['Port'] if row['is_bold'] else None, axis=1)\n",
    "\n",
    "    # Remove the is_bold helper column as it is no longer needed. You can uncomment ths for dbeugging purposes\n",
    "    df.drop(columns=['is_bold'], inplace=True)\n",
    "\n",
    "    df.dropna(how='all', inplace=True)  \n",
    "\n",
    "    df['Region'] = df['Region'].ffill()\n",
    "    df['PMO'] = df.groupby('Region')['PMO'].ffill()\n",
    "    df['Port'] = df.groupby(['Region', 'PMO'])['Port'].ffill()\n",
    "    df['Pier/Terminal'] = df.groupby(['Region', 'PMO', 'Port'])['Pier/Terminal'].ffill()\n",
    "\n",
    "    df['is_Region_base'] = df['Region'].notna() & df['PMO'].isna()\n",
    "    df['is_PMO_base'] = df['PMO'].notna() & df['Port'].isna()\n",
    "    df['is_Port_base'] = df['Port'].notna()\n",
    "    df['is_Pier/Terminal_base'] = df['Pier/Terminal'].notna()\n",
    "\n",
    "    return df\n",
    "\n",
    "file_name = 'RORO'\n",
    "\n",
    "for year in tqdm(YEARS[1:], desc=f\"Processing {file_name} data\"):\n",
    "    file_path = os.path.join('..', '[DATA] Ports Files', 'Raw Files', year, f'{file_name}.xlsx')\n",
    "    save_path = os.path.join('..', '[DATA] Ports Files', 'Standardized', file_name, f'{year} - {file_name}.{SAVE_FILE_TYPE}')\n",
    "    sheet_name = 'roro'\n",
    "    cleaned_data = preprocess_roro_data(file_path, sheet_name, 4) \n",
    "    cleaned_data.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Success!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20db9d1-d342-4dba-8df6-696c749e52fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
